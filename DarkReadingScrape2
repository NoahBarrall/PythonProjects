import csv
import requests
from bs4 import BeautifulSoup

# Make a request to the website
url = 'https://www.darkreading.com/attacks-breaches'
response = requests.get(url)

# Parse the HTML content
soup = BeautifulSoup(response.content, 'html.parser')

# Extract the information you want from the website
articles = []
for article in soup.find_all('div', class_='article-right ml-4 d-flex'):
    articles.append(article.text)

articles.sort(key=lambda x: x.title())

#Write the extracted information to a CSV file
with open('scrape/DarkReading.csv', 'w', newline='') as csvfile:
    writer = csv.writer(csvfile)
    writer.writerow(["Article Titles"])
    if articles: 
        for title in articles:
            writer.writerow([title + "\n"])
        print("Articles have been written to the csv file")
    else: 
        print("No articles have been found")
